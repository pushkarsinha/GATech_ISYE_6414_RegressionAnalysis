---
title: "HW1 Peer Assessment"
output:
  pdf_document: default
  html_document:
    df_print: paged
  word_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Part A. ANOVA

Additional Material: ANOVA tutorial

https://datascienceplus.com/one-way-anova-in-r/

Jet lag is a common problem for people traveling across multiple time zones, but people can gradually adjust to the new time zone since the exposure of the shifted light schedule to their eyes can resets the internal circadian rhythm in a process called “phase shift”. Campbell and Murphy (1998) in a highly controversial study reported that the human circadian clock can also be reset by only exposing the back of the knee to light, with some hailing this as a major discovery and others challenging aspects of the experimental design. The table below is taken from a later experiment by Wright and Czeisler (2002) that re-examined the phenomenon. The new experiment measured circadian rhythm through the daily cycle of melatonin production in 22 subjects randomly assigned to one of three light treatments. Subjects were woken from sleep and for three hours were exposed to bright lights applied to the eyes only, to the knees only or to neither (control group). The effects of treatment to the circadian rhythm were measured two days later by the magnitude of phase shift (measured in hours) in each subject’s daily cycle of melatonin production. A negative measurement indicates a delay in melatonin production, a predicted effect of light treatment, while a positive number indicates an advance.

Raw data of phase shift, in hours, for the circadian rhythm experiment

|Treatment|Phase Shift (hr)                            |
|:--------|:-------------------------------------------|
|Control  |0.53, 0.36, 0.20, -0.37, -0.60, -0.64, -0.68, -1.27|
|Knees    |0.73, 0.31, 0.03, -0.29, -0.56, -0.96, -1.61       |
|Eyes     |-0.78, -0.86, -1.35, -1.48, -1.52, -2.04, -2.83    |

## Question A1 - 3 pts

Consider the following incomplete R output:

|Source|Df |Sum of Squares|Mean Squares|F-statistics|p-value|
|:----:|:-:|:------------:|:----------:|:----------:|:-----:|
|Treatments|?|?|3.6122|?|0.004|
|Error|?|9.415|?| | |
|TOTAL|?|?| | | |

Fill in the missing values in the analysis of the variance table.

## Answer A1 

```{r}
treatement_shift_data = read.csv("Treatment_Phase_Shift.csv", header = TRUE)
treatement_shift_data
```


```{r}

library(ggplot2)
ggplot(treatement_shift_data, aes(x=Treatment, y=Phase_Shift_hr), 
       xlab = "Treatement", 
       ylab = "Phase Shift (hr)") + geom_boxplot() + 
  theme(axis.text.x  = element_text(angle=90, vjust=0.5))+
  ggtitle("Phase Shift (hr) with Respect to Treatement - ANOVA")

# apply ANOVA
model = aov(Phase_Shift_hr ~ Treatment, data=treatement_shift_data)

summary(model)

model.tables(model, type="means")
```


Complete R output:

|Source|Df |Sum of Squares|Mean Squares|F-statistics|p-value|
|:----:|:-:|:------------:|:----------:|:----------:|:-----:|
|Treatments|2|7.224|3.6122|7.289|0.004|
|Error|19|9.415|0.496| | |
|TOTAL|21|16.639| | | |


## Question A2 - 3 pts

Use $\mu_1$, $\mu_2$, and $\mu_3$  as notation for the three mean parameters and define these parameters clearly based on the context of the topic above. Find the estimates of these parameters.

## Answer A2 

```{r}
aggregate(treatement_shift_data[, 2], list(treatement_shift_data$Treatment), mean)

```
|Variable|Definition|Value|
|:----:|:------------:|:----------:|
|$\mu_1$ | Mean of Control Group | -0.3087500|
|$\mu_2$ | Mean of Eyes Group |-1.5514286|
|$\mu_3$ | Mean of Knees Group|-0.3357143|

## Question A3 - 5 pts

Use the ANOVA table in Question A1 to answer the following questions:

a. **1 pts** Write the null hypothesis of the ANOVA $F$-test, $H_0$

   **Answer : ** Null hypothesis means all means are equal - $\mu_1$ = $\mu_2$ = ... $\mu_k$. In this case Mean of Control Group = Mean of Eyes Group = Mean of Knees Group

b. **1 pts** Write the alternative hypothesis of the ANOVA $F$-test, $H_A$

   **Answer : ** Alternate Hypothesis means some means are different. Mean of Control group and Knees group appear to be similar but mean of Eyes group is different. This hsows atleast Eyes group mean is different from Control and Knees group

c. **1 pts** Fill in the blanks for the degrees of freedom of the ANOVA $F$-test statistic:   F(____,_____)
```{r}
nrow(treatement_shift_data)
length(unique(treatement_shift_data$Treatment))
```
   **Answer : ** $F$( k - 1, N - k) -> in above example it is **$F$( 2, 19)**

d. **1 pts** What is the p-value of the ANOVA $F$-test?
   
```{r}
#treatement_shift_data$Treatment
#treatement_shift_data$Phase_Shift_hr

model = aov(Phase_Shift_hr ~ Treatment, data=treatement_shift_data)
summary(model)
```
   **Answer ** - P-Value -  **0.00447**

e. **1 pts** According the the results of the ANOVA $F$-test, does light treatment affect phase shift?  Use an $\alpha$-level of 0.05.
```{r}
model.tables(model, type="means")
TukeyHSD(model)
```
  
  **Answer **  Since the p-values is less than $\alpha$-level of 0.05, we reject the null hypothesis that all means are equal. Thus the light treatement does affect Phase shift

# Part B. Simple Linear Regression

We are going to use regression analysis to estimate the performance of CPUs based on the maximum number of channels in the CPU.  This data set comes from the UCI Machine Learning Repository.

The data file includes the following columns:

* *vendor*: vendor of the CPU
* *chmax*: maximum channels in the CPU
* *performance*: published relative performance of the CPU

The data is in the file "machine.csv". To read the data in `R`, save the file in your working directory (make sure you have changed the directory if different from the R working directory) and read the data using the `R` function `read.csv()`.

```{r}
# Read in the data
data = read.csv("machine.csv", head = TRUE, sep = ",")
# Show the first few rows of data
head(data, 3)
```

## Question B1: Exploratory Data Analysis - 9 pts

a. **3 pts** Use a scatter plot to describe the relationship between CPU performance and the maximum number of channels. Describe the general trend (direction and form). Include plots and R-code used.

   **Answer:**  
```{r}
# Your code here...
plot(data$performance, data$chmax, 
     main="Scatterplot of CPU performance and the maximum number of channels", 
     xlab="CPU performance",
     ylab="maximum number of channels")

#plot(log(data$performance), log(data$chmax))
```

**Comments** : Scatter plot using original data does not show a good trend. Most of the points are clumped together towards the left bottom corner. When plotting the log of data points the graph starts to look a little more linear relationship

b. **3 pts** What is the value of the correlation coefficient between _performance_ and _chmax_? Please interpret the strength of the correlation based on the correlation coefficient.

   **Answer:**  
```{r}
# Your code here...
cor(data$performance, data$chmax)

```

**Answer** : correlation cofficient of 0.6052093 shows that the correlateion is above Modereate and not strong positive relationship

c. **2 pts** Based on this exploratory analysis, would you recommend a simple linear regression model for the relationship?

   **Answer:**  Based on the Exploratory data analysis there exists moderate relationship between the variables. I would still recommend Linear Regression for this... as there are a lot of datapoint for lower values of maximunnumber of  channles 

d. **1 pts** Based on the analysis above, would you pursue a transformation of the data? *Do not transform the data.*

    **Answer:**  Since th data is clumped together in the left bottom corner .. I would pursue data transformation before appling linear Regression to compare the model performace agains the one created without transformation

## Question B2: Fitting the Simple Linear Regression Model - 11 pts

Fit a linear regression model, named *model1*, to evaluate the relationship between performance and the maximum number of channels. *Do not transform the data.* The function you should use in R is:

```{r}
# Your code here...
model1 = lm(performance ~ chmax, data)
summary(model1)
confint(model1, level = 0.95)

pt(10.938, 207, lower.tail=FALSE)
```

a. **3 pts** What are the model parameters and what are their estimates?  
   **Answer:**  
   Model parameters 
     i. $\hat{\beta}_0$ - Intercept - 37.2252
     ii. $\hat{\beta}_1$ - Max #Channels - 3.7441
     iii. $\hat{\sigma}$ - Std Error- 128.3
     

b. **2 pts** Write down the estimated simple linear regression equation.

   **Answer:**  $performace = 37.2252 + 3.7441 \cdot chmax$

c. **2 pts** Interpret the estimated value of the $\beta_1$ parameter in the context of the problem.

   **Answer:**  For every unit of Maximum number of channels increase there is $\sim$ 3.7441 times increase in the CPU performance. 

d. **2 pts** Find a 95% confidence interval for the $\beta_1$ parameter. Is $\beta_1$ statistically significant at this level?

   **Answer:**  
   95 % confidence Interval for $\beta_1$ - 3.069251 - 4.418926
   
   $\beta_1$ is statistically significant as evidenced by p-value of 2e-16

e. **2 pts** Is $\beta_1$ statistically significantly positive at an $\alpha$-level of 0.01?  What is the approximate p-value of this test?

   **Answer:**  
   p-value is 1.424772e-22.. This shows that  $\beta_1$ statistically significantly positive at an $\alpha$-level of 0.01

## Question B3: Checking the Assumptions of the Model - 8 pts

Create and interpret the following graphs with respect to the assumptions of the linear regression model. In other words, comment on whether there are any apparent departures from the assumptions of the linear regression model. Make sure that you state the model assumptions and assess each one.  Each graph may be used to assess one or more model assumptions.

a. **2 pts** Scatterplot of the data with *chmax* on the x-axis and *performance* on the y-axis

```{r}
# Your code here...
plot(data$performance, data$chmax, 
     main="Scatterplot of CPU performance and the maximum number of channels", 
     xlab="CPU performance",
     ylab="maximum number of channels")
```

**Model Assumption(s) it checks:**
**Answer : ** Checks for Linearity Assumption.

**Interpretation:**
**Answer : ** The plot looks to have linear relationship.

b. **3 pts** Residual plot - a plot of the residuals, $\hat\epsilon_i$, versus the fitted values, $\hat{y}_i$

```{r}
# Your code here...
plot(model1$fitted, model1$residuals)
```

**Model Assumption(s) it checks:** 
**Answer : ** Checks for Constant variance

**Interpretation:** The fitted values vs residuals spread around 0 at random so it looks like the data satisfies Constant variance

c. **3 pts** Histogram and q-q plot of the residuals

```{r}
# Your code here...
library(car)
qqPlot(model1$residuals)
```

**Model Assumption(s) it checks:**
**Answer : ** Checks for Normality

**Interpretation:** The data mostly follows normal distribution but is heavy-tailed


## Question B4: Improving the Fit - 10 pts

a. **2 pts** Use a Box-Cox transformation (`boxCox()`) to find the optimal $\lambda$ value rounded to the nearest half integer.  What transformation of the response, if any, does it suggest to perform?

```{r}
# Your code here...
b = boxCox(data$performance ~ data$chmax)
lambda <- b$x # lambda values
lik <- b$y # log likelihood values for SSE
bc <- cbind(lambda, lik) # combine lambda and lik
sorted_bc <- bc[order(-lik),] # values are sorted to identify the lambda value for the maximum log likelihood for obtaining minimum SSE
head(sorted_bc, n = 10)
```
   **Answer :** the top $\lambda$ value suggests between -0.06 to -0.01. taking to nearest half integer.. it suggests $\lambda$ = 0
   
b. **2 pts** Create a linear regression model, named *model2*, that uses the log transformed *performance* as the response, and the log transformed *chmax* as the predictor. Note: The variable *chmax* has a couple of zero values which will cause problems when taking the natural log. Please add one to the predictor before taking the natural log of it

```{r}
# Your code here...
model2 = lm(log(performance) ~ log(chmax + 1), data)
summary(model2)
confint(model2, level = 0.95)

```

e. **2 pts** Compare the R-squared values of *model1* and *model2*.  Did the transformation improve the explanatory power of the model?

```{r}
summary(model1)$r.squared
summary(model2)$r.squared
```
   **Answer : ** Model1 -> $R^2$ = 0.3662783. Where as Model2 -> $R^2$ = 0.4102926

c. **4 pts** Similar to Question B3, assess and interpret all model assumptions of *model2*.  A model is considered a good fit if all assumptions hold. Based on your interpretation of the model assumptions, is *model2* a good fit?

**Model Assumption : ** Linearity Assumption.
```{r}
# Your code here...
plot(log(data$performance), log(data$chmax + 1), 
     main="Linearity Assumption", 
     xlab="CPU performance",
     ylab="maximum number of channels")
```

**Model Assumption : ** Constant variance.
```{r}
# Your code here...
plot(model2$fitted, model2$residuals, main="Constant Variance")
```

**Model Assumption : ** Normality

```{r}
# Your code here...
qqPlot(model2$residuals, main="Check for Normality")
```

## Question B5: Prediction - 3 pts

Suppose we are interested in predicting CPU performance when `chmax = 128`.  Please make a prediction using both *model1* and *model2* and provide the 95% prediction interval of each prediction on the original scale of the response, *performance*. What observations can you make about the result in the context of the problem?

```{r}
# Your code here...
# newppp= data.frame(Inflation.difference= c(-0.68))
newppp= data.frame(chmax= c(128))
predict(model1,newppp,interval=c("prediction"), level = 0.95)
exp(predict(model2,newppp,interval=c("prediction"), level = 0.95))
```


    **Answer : **

    1. Model 1 - the predicted value - 516.4685 with confidence interval of 252.2519 & 780.6851. The predicted value is high compared to model 2 but has smaller range.
    2. Model 2 - the predicted value - 277.723 with confidence interval of 55.17907 & 1397.813. The predicted value is lower than Model 1 and it has higher prediction intervel. 
      
    Looking at this .. seems like the Model 2 prediction has a tighter confidence interval and cab be deemed better than Model 2 prediction.

# Part C. ANOVA - 8 pts

We are going to continue using the CPU data set to analyse various vendors in the data set.  There are over 20 vendors in the data set.  To simplify the task, we are going to limit our analysis to three vendors, specifically, honeywell, hp, and nas.  The code to filter for those vendors is provided below.

```{r}
# Filter for honeywell, hp, and nas
data2 = data[data$vendor %in% c("honeywell", "hp", "nas"), ]
data2$vendor = factor(data2$vendor)
```

1. **2 pts** Using `data2`, create a boxplot of *performance* and *vendor*, with *performance* on the vertical axis.  Interpret the plots.  

```{r}
# Your code here...
ggplot(data2, aes(x=vendor, y=performance), 
       xlab = "Vendor", 
       ylab = "Performance") + 
  geom_boxplot() + 
  theme(axis.text.x  = element_text(angle=90, vjust=0.5))+
  ggtitle("Performance with Respect to Vendor")
```
  
  
   **Answer : **

    * honeywell and hp look to have similar mean
    * as seems to have higher mean that honeywell and hp
    * eventhough honewell has lower mean, there are some higher performance machines that they make


2. **3 pts** Perform an ANOVA F-test on the means of the three vendors.  Using an $\alpha$-level of 0.05, can we reject the null hypothesis that the means of the three vendors are equal?  Please interpret.

```{r}
# Your code here...
amodel = aov (data2$performance ~ data2$vendor)
summary(amodel)
```

   **Answer : ** The P-value of 0.00553 suggest that not all means are equal. Thus we reject the Null hypothesis and say that there are some means that are different. The Box Plot also shows the same thing

3. **3 pts** Perform a Tukey pairwise comparison between the three vendors. Using an $\alpha$-level of 0.05, which means are statistically significantly different from each other?

```{r}
# Your code here...
TukeyHSD(amodel)
```

   **ANSWER : ** Based on $\alpha$-level of 0.05 
   1. there are 2 pairs that are different nas-honeywell & nas-hp, 
   2. but hp-honeywell have similar means. 
   3. based on this we can conclude that hp and honeywell have same means. 
   4. but both honeywell and hp have means different for NAS. 
   5. Also both lower and upper thresholds for nas-honeywell and nas-hp are both positive.. so their means are not same
   
   
   
   
   
   